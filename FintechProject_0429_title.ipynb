{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FinTech Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing Transaction data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1  historical 2016 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_old = pd.read_csv('/Users/Stephanie_Zhang/Desktop/LendingClub项目/LoanStats3c.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 current 2017 data (import from Lending Club API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "header = { 'Authorization': 'MFlsdMVZe6dtdw/RzMruKtl6y1k='}\n",
    "r = requests.get(\"https://api.lendingclub.com/api/investor/v1/loans/listing\", headers = header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(r.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = r.json()\n",
    "myData = data['loans']\n",
    "with open('testdata.txt', 'w') as outfile:\n",
    "    json.dump(myData, outfile)\n",
    "df_Curr = pd.read_json('testdata.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_Curr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['accNowDelinq', 'accOpenPast24Mths', 'acceptD', 'addrState', 'addrZip',\n",
       "       'allUtil', 'annualInc', 'annualIncJoint', 'applicationType',\n",
       "       'avgCurBal',\n",
       "       ...\n",
       "       'totCollAmt', 'totCurBal', 'totHiCredLim', 'totalAcc', 'totalBalExMort',\n",
       "       'totalBalIl', 'totalBcLimit', 'totalCuTl', 'totalIlHighCreditLimit',\n",
       "       'totalRevHiLim'],\n",
       "      dtype='object', length=103)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Curr.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Column Name Adjustment for the data in 2016 and 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "listOld = []\n",
    "for column_name in df_old.columns.values:\n",
    "    Name = column_name.replace(\"_\",\"\")\n",
    "    listOld.append(Name)\n",
    "#     print (Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CapDown (string):\n",
    "    for i in range (len(string)):\n",
    "        string = string[0: i] + string[i].lower() + string[i+1:]\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "listCurr = []\n",
    "for column_name in df_Curr.columns.values:\n",
    "    listCurr.append(CapDown(column_name))\n",
    "#     print (CapDown(column_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Variable Column Compare between the data of 2016 and 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compareCol (list1, list2):\n",
    "    same = []\n",
    "    different = []\n",
    "    for i in range (len(list1)):\n",
    "        if list1[i] in list2:\n",
    "            same.append(list1[i])\n",
    "        else:\n",
    "            different.append(list1[i])\n",
    "    return same, different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acceptd', 'addrzip', 'creditpulld', 'desc', 'expd', 'expdefaultrate', 'ficorangehigh', 'ficorangelow', 'fundedamount', 'id', 'ilsexpd', 'investorcount', 'isincv', 'isincvjoint', 'listd', 'loanamount', 'memberid', 'numacctsever120ppd', 'reviewstatus', 'reviewstatusd', 'servicefeerate']\n",
      "['loanamnt', 'fundedamnt', 'fundedamntinv', 'verificationstatus', 'issued', 'loanstatus', 'pymntplan', 'title', 'zipcode', 'outprncp', 'outprncpinv', 'totalpymnt', 'totalpymntinv', 'totalrecprncp', 'totalrecint', 'totalreclatefee', 'recoveries', 'collectionrecoveryfee', 'lastpymntd', 'lastpymntamnt', 'nextpymntd', 'lastcreditpulld', 'policycode', 'verificationstatusjoint', 'numacctsever120pd']\n"
     ]
    }
   ],
   "source": [
    "sameCurr, differentCurr = compareCol(listCurr, listOld)\n",
    "sameOld, differentOld = compareCol(listOld, listCurr)\n",
    "print (differentCurr)\n",
    "print (differentOld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LCS (str1, str2):\n",
    "    m = len(str1)\n",
    "    n = len(str2)\n",
    "    max = 0\n",
    "    common = list()\n",
    "    count = [[0] * (n + 1) for x in range (m + 1)]\n",
    "    for i in range (m + 1):\n",
    "        count [i][0] = 0\n",
    "    for j in range (n + 1):\n",
    "        count [0][j] = 0\n",
    "    for i in range (1, m + 1):\n",
    "        for j in range (1, n + 1):\n",
    "            if str1[i - 1] == str2[j - 1]:\n",
    "                count[i][j] = count[i - 1][j - 1] + 1\n",
    "                if max < count[i][j]:\n",
    "                    max = count[i][j]\n",
    "                    common.append(str1[i - 1])\n",
    "            else:\n",
    "                count[i][j] = 0\n",
    "    return (max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print (LCS ('happy', 'halloppy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 creditpulld lastcreditpulld\n",
      "8 fundedamount fundedamnt\n",
      "8 fundedamount fundedamntinv\n",
      "5 isincvjoint verificationstatusjoint\n",
      "6 loanamount loanamnt\n",
      "4 loanamount loanstatus\n",
      "16 numacctsever120ppd numacctsever120pd\n",
      "6 reviewstatus verificationstatus\n",
      "6 reviewstatus loanstatus\n",
      "6 reviewstatus verificationstatusjoint\n",
      "6 reviewstatusd verificationstatus\n",
      "6 reviewstatusd loanstatus\n",
      "6 reviewstatusd verificationstatusjoint\n",
      "4 servicefeerate totalreclatefee\n"
     ]
    }
   ],
   "source": [
    "for i in range (len(differentCurr)):\n",
    "    for j in range (len(differentOld)):\n",
    "        if LCS (differentCurr[i], differentOld[j]) > 3 : \n",
    "            print (LCS (differentCurr[i], differentOld[j]), differentCurr[i], differentOld[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Adjust the Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rename according to the name comparison\n",
    "df_Curr.columns = listCurr\n",
    "df_old.columns = listOld\n",
    "# df_Curr.columns, df_old.columns\n",
    "\n",
    "df_Curr = df_Curr.rename(columns={'creditpulld': 'lastcreditpulld'})\n",
    "df_Curr = df_Curr.rename(columns={'fundedamount': 'fundedamnt'})\n",
    "df_Curr = df_Curr.rename(columns={'loanamount': 'loanamnt'})\n",
    "df_Curr = df_Curr.rename(columns={'numacctsever120ppd': 'numacctsever120pd'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acceptd', 'addrzip', 'desc', 'expd', 'expdefaultrate', 'ficorangehigh', 'ficorangelow', 'id', 'ilsexpd', 'investorcount', 'isincv', 'isincvjoint', 'listd', 'memberid', 'reviewstatus', 'reviewstatusd', 'servicefeerate']\n",
      "['fundedamntinv', 'verificationstatus', 'issued', 'loanstatus', 'pymntplan', 'title', 'zipcode', 'outprncp', 'outprncpinv', 'totalpymnt', 'totalpymntinv', 'totalrecprncp', 'totalrecint', 'totalreclatefee', 'recoveries', 'collectionrecoveryfee', 'lastpymntd', 'lastpymntamnt', 'nextpymntd', 'policycode', 'verificationstatusjoint']\n"
     ]
    }
   ],
   "source": [
    "# another round of calculating the same and difference list\n",
    "sameCurr2, differentCurr2 = compareCol(df_Curr.columns, df_old.columns)\n",
    "sameOld2, differentOld2 = compareCol(df_old.columns, df_Curr.columns)\n",
    "print (differentCurr2)\n",
    "print (differentOld2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# will delete the difference in new list differentCurr2\n",
    "for i in range(len(differentCurr2)):\n",
    "    df_Curr = df_Curr.drop(differentCurr2[i], 1)\n",
    "len(df_Curr.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# will delete the difference in new list differentOld2:\n",
    "for i in range(len(differentOld2)):\n",
    "    if differentOld2[i] != 'loanstatus' and differentOld2[i] != 'issued':\n",
    "        df_old = df_old.drop(differentOld2[i], 1)\n",
    "len(df_old.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Split train & test data, and aggregate into Full_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Target variable: loanstatus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fully Paid            114533\n",
      "Current                83597\n",
      "Charged Off            32263\n",
      "Late (31-120 days)      2737\n",
      "In Grace Period         1845\n",
      "Late (16-30 days)        647\n",
      "Default                    7\n",
      "Name: loanstatus, dtype: int64\n",
      "1    114533\n",
      "0     32263\n",
      "Name: loanstatus, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_old.loanstatus.value_counts())\n",
    "df_old = df_old.query(\"loanstatus == 'Fully Paid' or loanstatus == 'Charged Off'\")\n",
    "df_old['loanstatus'] = df_old.loanstatus.map({\"Charged Off\": 0, \"Fully Paid\": 1})\n",
    "# print(df_old.loanstatus)\n",
    "print(df_old.loanstatus.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Split into test and train data according to timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "df_old['issued'] = df_old.issued.apply(lambda x: x.split(\"-\")[0])\n",
    "df_test = df_old.query(\"issued =='Dec' or issued == 'Nov' or issued == 'Oct'\")\n",
    "df_train = df_old.query(\"issued !='Dec' and issued != 'Nov' and issued != 'Oct'\")\n",
    "df_test['flag'] = 0\n",
    "df_train['flag'] = 1\n",
    "df_Curr['flag'] = 2\n",
    "Full_data = pd.concat((df_test, df_train, df_Curr), axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89 146951\n",
      "87 88 103 107 155 146796\n"
     ]
    }
   ],
   "source": [
    "print(len(Full_data.columns), len(Full_data))\n",
    "print(len(df_Curr.columns), len(df_old.columns), len(listCurr), len(listOld), len(df_Curr), len(df_old))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grouping variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accnowdelinq :   int64\n",
      "accopenpast24mths :   int64\n",
      "addrstate :   object\n",
      "allutil :   float64\n",
      "annualinc :   float64\n",
      "annualincjoint :   float64\n",
      "applicationtype :   object\n",
      "avgcurbal :   float64\n",
      "bcopentobuy :   float64\n",
      "bcutil :   float64\n",
      "chargeoffwithin12mths :   int64\n",
      "collections12mthsexmed :   int64\n",
      "delinq2yrs :   int64\n",
      "delinqamnt :   int64\n",
      "dti :   float64\n",
      "dtijoint :   float64\n",
      "earliestcrline :   object\n",
      "emplength :   object\n",
      "emptitle :   object\n",
      "flag :   int64\n",
      "fundedamnt :   int64\n",
      "grade :   object\n",
      "homeownership :   object\n",
      "ilutil :   float64\n",
      "initialliststatus :   object\n",
      "inqfi :   float64\n",
      "inqlast12m :   float64\n",
      "inqlast6mths :   int64\n",
      "installment :   float64\n",
      "intrate :   object\n",
      "issued :   object\n",
      "lastcreditpulld :   object\n",
      "loanamnt :   int64\n",
      "loanstatus :   float64\n",
      "maxbalbc :   float64\n",
      "mortacc :   int64\n",
      "mosinoldilacct :   float64\n",
      "mosinoldrevtlop :   int64\n",
      "mosinrcntrevtlop :   int64\n",
      "mosinrcnttl :   int64\n",
      "mthssincelastdelinq :   float64\n",
      "mthssincelastmajorderog :   float64\n",
      "mthssincelastrecord :   float64\n",
      "mthssincercntil :   float64\n",
      "mthssincerecentbc :   float64\n",
      "mthssincerecentbcdlq :   float64\n",
      "mthssincerecentinq :   float64\n",
      "mthssincerecentrevoldelinq :   float64\n",
      "numacctsever120pd :   int64\n",
      "numactvbctl :   int64\n",
      "numactvrevtl :   int64\n",
      "numbcsats :   int64\n",
      "numbctl :   int64\n",
      "numiltl :   int64\n",
      "numoprevtl :   int64\n",
      "numrevaccts :   int64\n",
      "numrevtlbalgt0 :   int64\n",
      "numsats :   int64\n",
      "numtl120dpd2m :   float64\n",
      "numtl30dpd :   int64\n",
      "numtl90gdpd24m :   int64\n",
      "numtloppast12m :   int64\n",
      "openacc :   int64\n",
      "openacc6m :   float64\n",
      "openil12m :   float64\n",
      "openil24m :   float64\n",
      "openil6m :   float64\n",
      "openrv12m :   float64\n",
      "openrv24m :   float64\n",
      "pcttlnvrdlq :   float64\n",
      "percentbcgt75 :   float64\n",
      "pubrec :   int64\n",
      "pubrecbankruptcies :   int64\n",
      "purpose :   object\n",
      "revolbal :   int64\n",
      "revolutil :   object\n",
      "subgrade :   object\n",
      "taxliens :   int64\n",
      "term :   object\n",
      "totalacc :   int64\n",
      "totalbalexmort :   int64\n",
      "totalbalil :   float64\n",
      "totalbclimit :   int64\n",
      "totalcutl :   float64\n",
      "totalilhighcreditlimit :   int64\n",
      "totalrevhilim :   int64\n",
      "totcollamt :   int64\n",
      "totcurbal :   int64\n",
      "tothicredlim :   int64\n"
     ]
    }
   ],
   "source": [
    "for column_name in Full_data.columns.values:\n",
    "    print (column_name, \":  \", Full_data[column_name].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Checking with Null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accnowdelinq                   0\n",
       "accopenpast24mths              0\n",
       "addrstate                      0\n",
       "allutil                   146796\n",
       "annualinc                      0\n",
       "annualincjoint            146947\n",
       "applicationtype                0\n",
       "avgcurbal                      6\n",
       "bcopentobuy                 1497\n",
       "bcutil                      1608\n",
       "chargeoffwithin12mths          0\n",
       "collections12mthsexmed         0\n",
       "delinq2yrs                     0\n",
       "delinqamnt                     0\n",
       "dti                            0\n",
       "dtijoint                  146947\n",
       "earliestcrline                 0\n",
       "emplength                     13\n",
       "emptitle                    8238\n",
       "flag                           0\n",
       "fundedamnt                     0\n",
       "grade                          0\n",
       "homeownership                  0\n",
       "ilutil                    146821\n",
       "initialliststatus              0\n",
       "inqfi                     146796\n",
       "inqlast12m                146796\n",
       "inqlast6mths                   0\n",
       "installment                    0\n",
       "intrate                        0\n",
       "                           ...  \n",
       "numtl30dpd                     0\n",
       "numtl90gdpd24m                 0\n",
       "numtloppast12m                 0\n",
       "openacc                        0\n",
       "openacc6m                 146796\n",
       "openil12m                 146796\n",
       "openil24m                 146796\n",
       "openil6m                  146796\n",
       "openrv12m                 146796\n",
       "openrv24m                 146796\n",
       "pcttlnvrdlq                    0\n",
       "percentbcgt75               1575\n",
       "pubrec                         0\n",
       "pubrecbankruptcies             0\n",
       "purpose                        0\n",
       "revolbal                       0\n",
       "revolutil                     80\n",
       "subgrade                       0\n",
       "taxliens                       0\n",
       "term                           0\n",
       "totalacc                       0\n",
       "totalbalexmort                 0\n",
       "totalbalil                146796\n",
       "totalbclimit                   0\n",
       "totalcutl                 146796\n",
       "totalilhighcreditlimit         0\n",
       "totalrevhilim                  0\n",
       "totcollamt                     0\n",
       "totcurbal                      0\n",
       "tothicredlim                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Full_data.isnull().sum() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### drop null columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop null columns\n",
    "Full_data = Full_data.drop('openacc6m', 1)\n",
    "Full_data = Full_data.drop('openil12m', 1)\n",
    "Full_data = Full_data.drop('openil24m', 1)\n",
    "Full_data = Full_data.drop('openil6m', 1)\n",
    "Full_data = Full_data.drop('openrv12m', 1)\n",
    "Full_data = Full_data.drop('openrv24m', 1)\n",
    "Full_data = Full_data.drop('allutil', 1)\n",
    "Full_data = Full_data.drop('inqfi', 1)\n",
    "Full_data = Full_data.drop('inqlast12m', 1)\n",
    "Full_data = Full_data.drop('totalbalil', 1)\n",
    "Full_data = Full_data.drop('totalcutl', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check the Full_data again\n",
    "# np.sum(Full_data.isnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Grouping variables into continuous and categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['accnowdelinq', 'accopenpast24mths', 'annualinc', 'annualincjoint', 'avgcurbal', 'bcopentobuy', 'bcutil', 'chargeoffwithin12mths', 'collections12mthsexmed', 'delinq2yrs', 'delinqamnt', 'dti', 'dtijoint', 'flag', 'fundedamnt', 'ilutil', 'inqlast6mths', 'installment', 'loanamnt', 'loanstatus', 'maxbalbc', 'mortacc', 'mosinoldilacct', 'mosinoldrevtlop', 'mosinrcntrevtlop', 'mosinrcnttl', 'mthssincelastdelinq', 'mthssincelastmajorderog', 'mthssincelastrecord', 'mthssincercntil', 'mthssincerecentbc', 'mthssincerecentbcdlq', 'mthssincerecentinq', 'mthssincerecentrevoldelinq', 'numacctsever120pd', 'numactvbctl', 'numactvrevtl', 'numbcsats', 'numbctl', 'numiltl', 'numoprevtl', 'numrevaccts', 'numrevtlbalgt0', 'numsats', 'numtl120dpd2m', 'numtl30dpd', 'numtl90gdpd24m', 'numtloppast12m', 'openacc', 'pcttlnvrdlq', 'percentbcgt75', 'pubrec', 'pubrecbankruptcies', 'revolbal', 'taxliens', 'totalacc', 'totalbalexmort', 'totalbclimit', 'totalilhighcreditlimit', 'totalrevhilim', 'totcollamt', 'totcurbal', 'tothicredlim']\n",
      "['addrstate', 'applicationtype', 'earliestcrline', 'emplength', 'emptitle', 'grade', 'homeownership', 'initialliststatus', 'intrate', 'issued', 'lastcreditpulld', 'purpose', 'revolutil', 'subgrade', 'term']\n"
     ]
    }
   ],
   "source": [
    "# Value grouping into continuous and categorical\n",
    "Con_cols = [i for i in Full_data.columns if (Full_data.dtypes[i] =='float64' or Full_data.dtypes[i] == 'int64')]\n",
    "Cat_cols = [i for i in Full_data.columns if (i not in Con_cols) & (i !='id')]\n",
    "len(Con_cols), len(Cat_cols)\n",
    "print(Con_cols)\n",
    "print(Cat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 target variable distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    114533\n",
       "0.0     32263\n",
       "Name: loanstatus, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Full_data.loanstatus.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78 146951\n",
      "87 88 103 107 155 146796\n"
     ]
    }
   ],
   "source": [
    "print(len(Full_data.columns), len(Full_data))\n",
    "print(len(df_Curr.columns), len(df_old.columns), len(listCurr), len(listOld), len(df_Curr), len(df_old))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.1 Grade, subgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grade\n",
    "grade_dic = {\"A\": 1, \"B\": 2, \"C\": 3, \"D\": 4, \"E\":5, \"F\":6, \"G\":7} \n",
    "Full_data.grade = Full_data.grade.map(grade_dic)\n",
    "# subgrade\n",
    "Full_data.subgrade = Full_data.subgrade.apply(lambda x: (grade_dic[x[0]]) + int(x[1])/10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.2 Addrstate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# addrstate\n",
    "addrstate_freq = Full_data.groupby(\"addrstate\").size().reset_index()\n",
    "addrstate_freq.columns = [\"addrstate\", \"addrstate_freq\"]\n",
    "Full_data = pd.merge(Full_data, addrstate_freq, how = \"left\", on = \"addrstate\")\n",
    "# drop addrstate\n",
    "Full_data.drop('addrstate', axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.3 emptitle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#emptitle\n",
    "emptitle_freq = Full_data.groupby(\"emptitle\").size().reset_index()\n",
    "emptitle_freq.columns = [\"emptitle\", \"emptitle_freq\"]\n",
    "Full_data = pd.merge(Full_data, emptitle_freq, how = \"left\", on = \"emptitle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.4 null -> 'n/a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all data\n",
    "Full_data.replace('n/a', np.nan, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.5 intrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# intrate\n",
    "Full_data.intrate = pd.Series(Full_data.intrate).str.replace('%', '').astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.6 revoluntil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# revoluntil\n",
    "Full_data.revolutil = pd.Series(Full_data.revolutil).str.replace('%', '').astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.7 emplength (drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full_data.emplength ---deleted, for current data is not consistant with the historical data，\n",
    "# which was supposed to be 1-10 years\n",
    "Full_data = Full_data.drop('emplength', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.8 categorical variables - one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dummy = [\"applicationtype\", \"homeownership\",\"initialliststatus\", \"purpose\",\"term\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "# lets try if label encoder can replace np.nan\n",
    "# full_data = full_data.replace(np.nan, 'null')\n",
    "\n",
    "for col in dummy:\n",
    "    print (\"Label encoding  %s\" % (col))\n",
    "    LBL = preprocessing.LabelEncoder() #1\n",
    "    LBL.fit(Full_data[col])#2\n",
    "    labels = dict(zip(Full_data[col].unique()\n",
    "               , LBL.transform(Full_data[col].unique())))\n",
    "    print (labels)\n",
    "    print (LBL.classes_)\n",
    "    Full_data[col]=LBL.transform(Full_data[col])#3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'applicationtype','homeownership','initialliststatus','purpose'\n",
    "one_hot = pd.get_dummies(Full_data['homeownership'])\n",
    "Full_data = Full_data.drop('homeownership', axis =1)\n",
    "Full_data = Full_data.join(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Full_data.columns = Full_data.columns.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  rename \n",
    "Full_data = Full_data.rename(columns={'0': 'homeownership_0'})\n",
    "Full_data = Full_data.rename(columns={'1': 'homeownership_1'})\n",
    "Full_data = Full_data.rename(columns={'2': 'homeownership_2'})\n",
    "Full_data = Full_data.rename(columns={'3': 'homeownership_3'})\n",
    "# Full_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot1 = pd.get_dummies(Full_data['initialliststatus'])\n",
    "Full_data = Full_data.drop('initialliststatus', axis =1)\n",
    "Full_data = Full_data.join(one_hot1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Full_data.columns = Full_data.columns.astype(str)\n",
    "Full_data = Full_data.rename(columns={'0': 'initialliststatus_0'})\n",
    "Full_data = Full_data.rename(columns={'1': 'initialliststatus_1'})\n",
    "Full_data = Full_data.rename(columns={'2': 'initialliststatus_2'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot3 = pd.get_dummies(Full_data['purpose'])\n",
    "Full_data = Full_data.drop('purpose', axis =1)\n",
    "Full_data = Full_data.join(one_hot3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "Full_data.columns = Full_data.columns.astype(str)\n",
    "Full_data = Full_data.rename(columns={'0': 'purpuse_0'})\n",
    "Full_data = Full_data.rename(columns={'1': 'purpuse_1'})\n",
    "Full_data = Full_data.rename(columns={'2': 'purpuse_2'})\n",
    "Full_data = Full_data.rename(columns={'3': 'purpuse_3'})\n",
    "Full_data = Full_data.rename(columns={'4': 'purpuse_4'})\n",
    "Full_data = Full_data.rename(columns={'5': 'purpuse_5'})\n",
    "Full_data = Full_data.rename(columns={'6': 'purpuse_6'})\n",
    "Full_data = Full_data.rename(columns={'7': 'purpuse_7'})\n",
    "Full_data = Full_data.rename(columns={'8': 'purpuse_8'})\n",
    "Full_data = Full_data.rename(columns={'9': 'purpuse_9'})\n",
    "Full_data = Full_data.rename(columns={'10': 'purpuse_10'})\n",
    "Full_data = Full_data.rename(columns={'11': 'purpuse_11'})\n",
    "Full_data = Full_data.rename(columns={'12': 'purpuse_12'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot4 = pd.get_dummies(Full_data['applicationtype'])\n",
    "Full_data = Full_data.drop('applicationtype', axis =1)\n",
    "Full_data = Full_data.join(one_hot4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Full_data = Full_data.rename(columns={'0': 'applicationtype_0'})\n",
    "Full_data = Full_data.rename(columns={'1': 'applicationtype_1'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.9 Drop Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i dropped three columns that there is little to deal with for now.\n",
    "Full_data = Full_data.drop('term', axis = 1)\n",
    "Full_data = Full_data.drop('earliestcrline', axis = 1)\n",
    "Full_data = Full_data.drop('lastcreditpulld', axis = 1)\n",
    "Full_data = Full_data.drop('addrstate', axis = 1) #BEFORE SHOULD HAVE DELETED\n",
    "Full_data = Full_data.drop('emptitle', axis = 1) #BEFORE SHOULD HAVE DELETED\n",
    "Full_data = Full_data.drop('issued', axis = 1) #BEFORE SHOULD HAVE DELETED\n",
    "# drop the nan\n",
    "Full_data = Full_data.drop('annualincjoint', axis = 1)\n",
    "Full_data = Full_data.drop('dtijoint', axis = 1)\n",
    "Full_data = Full_data.drop('ilutil', axis = 1)\n",
    "Full_data = Full_data.drop('maxbalbc', axis = 1)\n",
    "Full_data = Full_data.drop('mthssincercntil', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.10 Fill NA with median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "Full_data = Full_data.fillna(Full_data.median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Train & Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = Full_data.loc[Full_data['flag'] == 0]\n",
    "test = Full_data.loc[Full_data['flag'] == 1]\n",
    "test_predict = Full_data.loc[Full_data['flag'] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37577 109219 155\n",
      "146951\n"
     ]
    }
   ],
   "source": [
    "print (len(train), len(test), len(test_predict))\n",
    "print (len(Full_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = train.drop(\"loanstatus\", axis=1)\n",
    "Y_train = train[\"loanstatus\"]\n",
    "X_test = test.drop(\"loanstatus\", axis=1)\n",
    "Y_test = test[\"loanstatus\"]\n",
    "X_test_predict = test_predict.drop(\"loanstatus\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37577 85 37577\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train), len(X_train.columns), len(Y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:   train set: 37577,   test set: 109219,   predict: 155 ,  85 variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Model Selection & Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accnowdelinq</th>\n",
       "      <th>accopenpast24mths</th>\n",
       "      <th>annualinc</th>\n",
       "      <th>avgcurbal</th>\n",
       "      <th>bcopentobuy</th>\n",
       "      <th>bcutil</th>\n",
       "      <th>chargeoffwithin12mths</th>\n",
       "      <th>collections12mthsexmed</th>\n",
       "      <th>delinq2yrs</th>\n",
       "      <th>delinqamnt</th>\n",
       "      <th>...</th>\n",
       "      <th>purpuse_5</th>\n",
       "      <th>purpuse_6</th>\n",
       "      <th>purpuse_7</th>\n",
       "      <th>purpuse_8</th>\n",
       "      <th>purpuse_9</th>\n",
       "      <th>purpuse_10</th>\n",
       "      <th>purpuse_11</th>\n",
       "      <th>purpuse_12</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>58000.0</td>\n",
       "      <td>9536.0</td>\n",
       "      <td>7599.0</td>\n",
       "      <td>41.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>78000.0</td>\n",
       "      <td>29828.0</td>\n",
       "      <td>9525.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>63800.0</td>\n",
       "      <td>4232.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>97.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>5857.0</td>\n",
       "      <td>332.0</td>\n",
       "      <td>93.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   accnowdelinq  accopenpast24mths  annualinc  avgcurbal  bcopentobuy  bcutil  \\\n",
       "0             0                  7    58000.0     9536.0       7599.0    41.5   \n",
       "1             0                  5    78000.0    29828.0       9525.0     4.7   \n",
       "2             0                  4    63800.0     4232.0        324.0    97.8   \n",
       "3             0                  6    50000.0     5857.0        332.0    93.2   \n",
       "\n",
       "   chargeoffwithin12mths  collections12mthsexmed  delinq2yrs  delinqamnt ...   \\\n",
       "0                      0                       0           0           0 ...    \n",
       "1                      0                       0           0           0 ...    \n",
       "2                      0                       0           0           0 ...    \n",
       "3                      0                       0           0           0 ...    \n",
       "\n",
       "   purpuse_5  purpuse_6  purpuse_7  purpuse_8  purpuse_9  purpuse_10  \\\n",
       "0        0.0        0.0        0.0        0.0        0.0         0.0   \n",
       "1        0.0        0.0        0.0        0.0        0.0         0.0   \n",
       "2        0.0        0.0        0.0        0.0        0.0         0.0   \n",
       "3        0.0        0.0        0.0        0.0        0.0         0.0   \n",
       "\n",
       "   purpuse_11  purpuse_12    0    1  \n",
       "0         0.0         0.0  1.0  0.0  \n",
       "1         0.0         0.0  1.0  0.0  \n",
       "2         0.0         0.0  1.0  0.0  \n",
       "3         0.0         0.0  1.0  0.0  \n",
       "\n",
       "[4 rows x 86 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Full_data.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Check Null\n",
    "# Full_data.iloc[:,1:40].isnull().sum() \n",
    "# Full_data.iloc[:,41:90].isnull().sum() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "RF = RandomForestClassifier()#linearregression\n",
    "RF = RF.fit(X_train, Y_train)\n",
    "y_pred = RF.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.35      0.27      0.30     22873\n",
      "        1.0       0.82      0.87      0.84     86346\n",
      "\n",
      "avg / total       0.72      0.74      0.73    109219\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (metrics.classification_report(Y_test, y_pred))# accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc = DecisionTreeClassifier(max_depth=5)  #(可以改max depth)\n",
    "dtc.fit(X_train,Y_train)\n",
    "y_pred1 = dtc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.44      0.11      0.18     22873\n",
      "        1.0       0.80      0.96      0.88     86346\n",
      "\n",
      "avg / total       0.73      0.78      0.73    109219\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (metrics.classification_report(Y_test, y_pred1))# accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Parameter tuning: Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics, grid_search\n",
    "from sklearn.model_selection import cross_val_score\n",
    "def search_model(x_train, y_train, est, param_grid, n_jobs, cv, refit=False):\n",
    "##Grid Search for the best model\n",
    "    model = grid_search.GridSearchCV(estimator  = est,\n",
    "                                     param_grid = param_grid,\n",
    "                                     scoring    = 'f1_weighted',\n",
    "                                     verbose    = 10,\n",
    "                                     n_jobs  = n_jobs,\n",
    "                                     iid    = True,\n",
    "                                     refit    = refit,\n",
    "                                     cv      = cv)\n",
    "    # Fit Grid Search Model\n",
    "    model.fit(x_train, y_train)\n",
    "#     print(\"Best score: %0.3f\" % model.best_score_)\n",
    "#     print(\"Best parameters set:\", model.best_params_)\n",
    "#     print(\"Scores:\", model.grid_scores_)    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "param_grid = {'n_estimators':[100,300,500],\n",
    "             'criterion':['gini', 'entropy']}\n",
    "\n",
    "RF = search_model(X_train.values\n",
    "            , Y_train.values\n",
    "            , RandomForestClassifier()\n",
    "            , param_grid\n",
    "            , -1\n",
    "            , 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Voting ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.70 (+/- 0.01) [Random_Forest]\n",
      "Accuracy: 0.67 (+/- 0.00) [KNN]\n",
      "Accuracy: 0.69 (+/- 0.00) [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "# voting ensemble\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "clf1 = RandomForestClassifier(n_estimators = 500, random_state = 1234, criterion = 'entropy')\n",
    "# results from your gridsearch\n",
    "clf2 = KNeighborsClassifier(n_neighbors=3)\n",
    "# results from your gridsearch\n",
    "eclf = VotingClassifier(estimators=[('Random_Forest',clf1), ('KNN', clf2)], voting='hard')\n",
    "for clf, label in zip([clf1, clf2, eclf], ['Random_Forest', 'KNN', 'Ensemble']):\n",
    "    scores = cross_val_score(clf, X_train, Y_train, cv=5, scoring='f1_weighted')\n",
    "    print (\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('Random_Forest', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "...owski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
       "           weights='uniform'))],\n",
       "         n_jobs=1, voting='hard', weights=None)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eclf.fit(X_train, Y_train)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
